"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[251],{963:(e,n,t)=>{t.d(n,{A:()=>i});t(6540);var r=t(4164);const a={callout:"callout_jYHE",info:"info_IOty",tip:"tip_s2nh",caution:"caution_w7Js",danger:"danger_zfsw",icon:"icon_Ghiv",content:"content_JMk4"};var s=t(4848);function i({type:e,children:n}){const t=function(e){switch(e){case"info":default:return"\u2139\ufe0f";case"tip":return"\ud83d\udca1";case"caution":return"\u26a0\ufe0f";case"danger":return"\u274c"}}(e),i=(0,r.A)("callout",a.callout,a[e]);return(0,s.jsxs)("div",{className:i,children:[(0,s.jsx)("div",{className:a.icon,children:t}),(0,s.jsx)("div",{className:a.content,children:n})]})}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>o});var r=t(6540);const a={},s=r.createContext(a);function i(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),r.createElement(s.Provider,{value:n},e.children)}},8530:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>g,frontMatter:()=>o,metadata:()=>r,toc:()=>p});const r=JSON.parse('{"id":"module-4-vla/chapter-18-cognitive-planning","title":"Chapter 18 - Cognitive Planning","description":"Learning Objectives","source":"@site/docs/module-4-vla/chapter-18-cognitive-planning.mdx","sourceDirName":"module-4-vla","slug":"/module-4-vla/chapter-18-cognitive-planning","permalink":"/humanoid-robotics/docs/module-4-vla/chapter-18-cognitive-planning","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedBy":"Muhammad Uzair","lastUpdatedAt":1765045729000,"sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Chapter 18 - Cognitive Planning"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 17 - Voice to Action","permalink":"/humanoid-robotics/docs/module-4-vla/chapter-17-voice-to-action"},"next":{"title":"Chapter 19 - Multi-Modal Interaction","permalink":"/humanoid-robotics/docs/module-4-vla/chapter-19-multi-modal-interaction"}}');var a=t(4848),s=t(8453),i=t(963);const o={sidebar_position:3,title:"Chapter 18 - Cognitive Planning"},l="Chapter 18: Cognitive Planning for Robotics",c={},p=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Content with Code Examples",id:"content-with-code-examples",level:2},{value:"Mermaid Diagrams",id:"mermaid-diagrams",level:2},{value:"Callouts",id:"callouts",level:2},{value:"Exercises",id:"exercises",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"chapter-18-cognitive-planning-for-robotics",children:"Chapter 18: Cognitive Planning for Robotics"})}),"\n",(0,a.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(n.p,{children:"After completing this chapter, you should be able to:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Understand cognitive planning approaches in robotics"}),"\n",(0,a.jsx)(n.li,{children:"Implement planning systems that integrate knowledge and perception"}),"\n",(0,a.jsx)(n.li,{children:"Design planning systems that can adapt to changing environments"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"content-with-code-examples",children:"Content with Code Examples"}),"\n",(0,a.jsx)(n.p,{children:"Cognitive planning in robotics involves creating systems that can reason about complex tasks, integrate knowledge from various sources, and adapt their plans based on changing conditions."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from enum import Enum\r\nfrom dataclasses import dataclass\r\nfrom typing import List, Dict, Optional\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom geometry_msgs.msg import PoseStamped\r\nfrom std_msgs.msg import String\r\nfrom sensor_msgs.msg import Image\r\nimport json\r\n\r\nclass TaskType(Enum):\r\n    NAVIGATE = "navigate"\r\n    MANIPULATE = "manipulate"\r\n    PERCEIVE = "perceive"\r\n    COMMUNICATE = "communicate"\r\n\r\nclass ObjectState(Enum):\r\n    UNKNOWN = "unknown"\r\n    PRESENT = "present"\r\n    ABSENT = "absent"\r\n    GRASPED = "grasped"\r\n\r\n@dataclass\r\nclass RobotState:\r\n    position: tuple  # (x, y, theta)\r\n    battery_level: float\r\n    objects: Dict[str, ObjectState]\r\n    last_perception_time: float\r\n\r\n@dataclass\r\nclass Task:\r\n    task_type: TaskType\r\n    target: str\r\n    parameters: Dict = None\r\n    priority: int = 1\r\n\r\nclass CognitivePlanner(Node):\r\n    def __init__(self):\r\n        super().__init__(\'cognitive_planner\')\r\n        \r\n        # Initialize robot state\r\n        self.robot_state = RobotState(\r\n            position=(0, 0, 0),\r\n            battery_level=1.0,\r\n            objects={},\r\n            last_perception_time=0\r\n        )\r\n        \r\n        # Initialize task queue\r\n        self.task_queue: List[Task] = []\r\n        \r\n        # Publishers\r\n        self.nav_goal_pub = self.create_publisher(PoseStamped, \'/goal_pose\', 10)\r\n        self.task_status_pub = self.create_publisher(String, \'/task_status\', 10)\r\n        \r\n        # Subscribers\r\n        self.perception_sub = self.create_subscription(\r\n            String, \r\n            \'/perception_update\', \r\n            self.perception_callback, \r\n            10\r\n        )\r\n        \r\n        self.command_sub = self.create_subscription(\r\n            String, \r\n            \'/high_level_command\', \r\n            self.command_callback, \r\n            10\r\n        )\r\n        \r\n        # Timer for planning cycle\r\n        self.planner_timer = self.create_timer(1.0, self.planning_cycle)\r\n\r\n    def perception_callback(self, msg: String):\r\n        """Update robot state based on perception"""\r\n        try:\r\n            perception_data = json.loads(msg.data)\r\n            self.robot_state.last_perception_time = self.get_clock().now().nanoseconds / 1e9\r\n            \r\n            # Update object states\r\n            if \'objects\' in perception_data:\r\n                for obj_name, obj_state in perception_data[\'objects\'].items():\r\n                    self.robot_state.objects[obj_name] = ObjectState(obj_state)\r\n                    \r\n            # Update position if available\r\n            if \'position\' in perception_data:\r\n                self.robot_state.position = tuple(perception_data[\'position\'])\r\n                \r\n        except Exception as e:\r\n            self.get_logger().error(f\'Error processing perception update: {e}\')\r\n\r\n    def command_callback(self, msg: String):\r\n        """Add high-level command to task queue"""\r\n        try:\r\n            command_data = json.loads(msg.data)\r\n            task_type_str = command_data.get(\'task_type\', \'navigate\')\r\n            \r\n            # Convert string to enum\r\n            try:\r\n                task_type = TaskType(task_type_str.upper())\r\n            except ValueError:\r\n                self.get_logger().error(f\'Invalid task type: {task_type_str}\')\r\n                return\r\n            \r\n            task = Task(\r\n                task_type=task_type,\r\n                target=command_data.get(\'target\', \'\'),\r\n                parameters=command_data.get(\'parameters\', {}),\r\n                priority=command_data.get(\'priority\', 1)\r\n            )\r\n            \r\n            # Insert task based on priority\r\n            inserted = False\r\n            for i, t in enumerate(self.task_queue):\r\n                if task.priority > t.priority:\r\n                    self.task_queue.insert(i, task)\r\n                    inserted = True\r\n                    break\r\n            \r\n            if not inserted:\r\n                self.task_queue.append(task)\r\n                \r\n            self.get_logger().info(f\'Added task: {task.task_type.value} to {task.target}\')\r\n            \r\n        except Exception as e:\r\n            self.get_logger().error(f\'Error processing command: {e}\')\r\n\r\n    def planning_cycle(self):\r\n        """Main cognitive planning cycle"""\r\n        if not self.task_queue:\r\n            return\r\n            \r\n        # Get the highest priority task\r\n        current_task = self.task_queue[0]\r\n        \r\n        # Check preconditions and update plan if needed\r\n        if self.check_task_preconditions(current_task):\r\n            # Execute task\r\n            self.execute_task(current_task)\r\n            \r\n            # Remove completed task\r\n            self.task_queue.pop(0)\r\n            \r\n            # Publish task completion\r\n            status_msg = String()\r\n            status_msg.data = f\'Task completed: {current_task.task_type.value} to {current_task.target}\'\r\n            self.task_status_pub.publish(status_msg)\r\n        else:\r\n            # Replan or wait\r\n            status_msg = String()\r\n            status_msg.data = f\'Waiting to satisfy preconditions for: {current_task.task_type.value}\'\r\n            self.task_status_pub.publish(status_msg)\r\n\r\n    def check_task_preconditions(self, task: Task) -> bool:\r\n        """Check if preconditions for task are satisfied"""\r\n        if task.task_type == TaskType.NAVIGATE:\r\n            # Navigation typically always possible (unless battery too low)\r\n            return self.robot_state.battery_level > 0.1\r\n        elif task.task_type == TaskType.MANIPULATE:\r\n            # Manipulation requires the object to be present\r\n            required_object = task.target\r\n            return (\r\n                self.robot_state.objects.get(required_object, ObjectState.UNKNOWN) == ObjectState.PRESENT\r\n            )\r\n        elif task.task_type == TaskType.PERCEIVE:\r\n            # Perception is always possible\r\n            return True\r\n        else:\r\n            return True\r\n\r\n    def execute_task(self, task: Task):\r\n        """Execute the given task"""\r\n        if task.task_type == TaskType.NAVIGATE:\r\n            self.execute_navigation_task(task)\r\n        elif task.task_type == TaskType.MANIPULATE:\r\n            self.execute_manipulation_task(task)\r\n        elif task.task_type == TaskType.PERCEIVE:\r\n            self.execute_perception_task(task)\r\n        elif task.task_type == TaskType.COMMUNICATE:\r\n            self.execute_communication_task(task)\r\n\r\n    def execute_navigation_task(self, task: Task):\r\n        """Execute navigation task"""\r\n        # In a real implementation, this would parse the target and publish a navigation goal\r\n        self.get_logger().info(f\'Navigating to: {task.target}\')\r\n        \r\n        # For this example, we\'ll just publish a dummy goal\r\n        goal_msg = PoseStamped()\r\n        goal_msg.header.stamp = self.get_clock().now().to_msg()\r\n        goal_msg.header.frame_id = \'map\'\r\n        goal_msg.pose.position.x = 1.0  # Example coordinates\r\n        goal_msg.pose.position.y = 1.0\r\n        goal_msg.pose.position.z = 0.0\r\n        goal_msg.pose.orientation.w = 1.0\r\n        \r\n        self.nav_goal_pub.publish(goal_msg)\r\n\r\n    def execute_manipulation_task(self, task: Task):\r\n        """Execute manipulation task"""\r\n        self.get_logger().info(f\'Manipulating object: {task.target}\')\r\n        # Implementation would depend on the specific manipulation system\r\n\r\n    def execute_perception_task(self, task: Task):\r\n        """Execute perception task"""\r\n        self.get_logger().info(f\'Performing perception task: {task.target}\')\r\n        # Implementation would trigger appropriate perception routines\r\n\r\n    def execute_communication_task(self, task: Task):\r\n        """Execute communication task"""\r\n        self.get_logger().info(f\'Communicating: {task.target}\')\r\n        # Implementation would trigger speech or other communication\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    planner = CognitivePlanner()\r\n    \r\n    try:\r\n        rclpy.spin(planner)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        planner.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,a.jsx)(n.h2,{id:"mermaid-diagrams",children:"Mermaid Diagrams"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-mermaid",children:"graph TD;\r\n    A[High-Level Goal] --\x3e B[Cognitive Planner]\r\n    B --\x3e C[Task Decomposition]\r\n    C --\x3e D[State Assessment]\r\n    D --\x3e E[Plan Generation]\r\n    E --\x3e F[Plan Execution]\r\n    F --\x3e G[Monitor & Adapt]\r\n    G --\x3e H{Plan Successful?}\r\n    H --\x3e|No| I[Plan Reconsideration]\r\n    H --\x3e|Yes| J[Next Task]\r\n    I --\x3e B\r\n    J --\x3e B\r\n    K[Sensor Data] --\x3e B\r\n    L[Knowledge Base] --\x3e B\r\n    M[Robot Capabilities] --\x3e B\n"})}),"\n",(0,a.jsx)(n.h2,{id:"callouts",children:"Callouts"}),"\n",(0,a.jsx)(i.A,{type:"info",children:(0,a.jsx)(n.p,{children:"Cognitive planning systems maintain a model of the world state and reason about how to achieve goals based on that model."})}),"\n",(0,a.jsx)(i.A,{type:"tip",children:(0,a.jsx)(n.p,{children:"Implement plan monitoring to detect when execution is not proceeding as expected, triggering replanning when necessary."})}),"\n",(0,a.jsx)(i.A,{type:"caution",children:(0,a.jsx)(n.p,{children:"Cognitive planning can be computationally intensive. Consider hierarchical approaches to make planning tractable for complex tasks."})}),"\n",(0,a.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Implement a cognitive planner for a simple pick-and-place task"}),"\n",(0,a.jsx)(n.li,{children:"Add plan monitoring and replanning capabilities"}),"\n",(0,a.jsx)(n.li,{children:"Integrate knowledge about object affordances into the planning system"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Cognitive planning considers world state and task requirements for decision making"}),"\n",(0,a.jsx)(n.li,{children:"Planning systems must handle uncertainty and adapt to changing conditions"}),"\n",(0,a.jsx)(n.li,{children:"Hierarchical planning helps manage complexity in cognitive systems"}),"\n"]})]})}function g(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);